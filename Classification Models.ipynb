{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: THE RUNTIME OF THIS SCRIPT IS AROUND 20 MINUTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import revelant modules\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    import seaborn as sns\n",
    "except:\n",
    "    !pip install seaborn\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read both training and testing data sets and put into dataframe objects\n",
    "training_data = pd.read_csv(\"income-training.csv\")\n",
    "test_data  = pd.read_csv(\"income-testing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Feature \n",
    "Create a new feature called \"Negative_Investment\" based on the \"CapitalGain\" and \"CaptitalLoss\" values.\n",
    "eg. If the CapitalGain is less than CapitalLoss then assign 1, which is a reprensentation of negative invetment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#New feature is added to the end of orignal dataframe as a new column with 1 as yes and 0 as no\n",
    "training_data['Negative_Investment'] = np.where((training_data['CapitalGain'] < training_data['CapitalLoss']), 1, 0) \n",
    "test_data['Negative_Investment'] = np.where((test_data['CapitalGain'] < test_data['CapitalLoss']), 1, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24421 entries, 0 to 24420\n",
      "Data columns (total 16 columns):\n",
      "Age                    24421 non-null int64\n",
      "WorkClass              23037 non-null object\n",
      "FinalWeight            24421 non-null int64\n",
      "Education              24421 non-null object\n",
      "EducationLvl           24421 non-null int64\n",
      "MaritalStatus          24421 non-null object\n",
      "Occupation             23031 non-null object\n",
      "Relationship           24421 non-null object\n",
      "Race                   24421 non-null object\n",
      "Sex                    24421 non-null object\n",
      "CapitalGain            24421 non-null int64\n",
      "CapitalLoss            24421 non-null int64\n",
      "HoursPerWeek           24421 non-null int64\n",
      "NativeCountry          24026 non-null object\n",
      "IncomeBracket          24421 non-null object\n",
      "Negative_Investment    24421 non-null int64\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 3.0+ MB\n",
      "None\n",
      "\n",
      "=======================================\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12211 entries, 0 to 12210\n",
      "Data columns (total 16 columns):\n",
      "Age                    12211 non-null int64\n",
      "WorkClass              11523 non-null object\n",
      "FinalWeight            12211 non-null int64\n",
      "Education              12211 non-null object\n",
      "EducationLvl           12211 non-null int64\n",
      "MaritalStatus          12211 non-null object\n",
      "Occupation             11521 non-null object\n",
      "Relationship           12211 non-null object\n",
      "Race                   12211 non-null object\n",
      "Sex                    12211 non-null object\n",
      "CapitalGain            12211 non-null int64\n",
      "CapitalLoss            12211 non-null int64\n",
      "HoursPerWeek           12211 non-null int64\n",
      "NativeCountry          11986 non-null object\n",
      "IncomeBracket          12211 non-null object\n",
      "Negative_Investment    12211 non-null int64\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 1.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#print both datasets information, so we can check how many line items we have and if any empty cells\n",
    "print(training_data.info())\n",
    "print(\"\\n=======================================\\n\")\n",
    "print(test_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only \"WorkClass\", \"Occupation\", \"NativeCountry\" have empty cells.\n",
    "Reasons behind these empty cells for Occupation and WorkClass maybe due to the fact that these people are currently\n",
    "unemployeded thus leaving these two columns blank, while the absent information of \"NativeCountry\" may be explained by the hesitations that some people have to disclose their Native Country for security reasons.\n",
    "\n",
    "#### High Level Summary\n",
    "training_data:\n",
    "\n",
    "               24421 rows in total;\n",
    "               1384 empty cells for WorkClass;\n",
    "               1390 empty cells for Occupation;\n",
    "               395 empty cells for NativeCountry;\n",
    "test_data:\n",
    "\n",
    "               12211 rows in total;\n",
    "               688 empty cells for WorkClass;\n",
    "               690 empty cells for Occupation;\n",
    "               225 empty cells for NativeCountry;\n",
    "As these are all categorical data, I will find out the mode for each and fill in the empty cells with the modes.\n",
    "The effect it can bring in is making the mode more significant eg, the feature key becomes more apparent or statistically significant. However, comparing to the totoal number of rows/datapoints we have, the number of missing values for each feature is insignificant so it may not produce a very pronounced drawback, but will help us better capture the most significant(mode) key thus helping to prepare the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define a clean function that will fill in empty cells and convert categorical data to numerical data\n",
    "def clean(df):\n",
    "    \n",
    "    #find out the mode for each feature\n",
    "    WorkClass_mode = df.WorkClass.mode().to_string(index=False)\n",
    "    Occupation_mode = df.Occupation.mode().to_string(index=False)\n",
    "    NativeCountry_mode = df.NativeCountry.mode().to_string(index=False)\n",
    "\n",
    "    #fill in the mode values to each empty cell for each feature\n",
    "    df.set_value(df.WorkClass.isnull(), 'WorkClass', WorkClass_mode)\n",
    "    df.set_value(df.Occupation.isnull(), 'Occupation', Occupation_mode)\n",
    "    df.set_value(df.NativeCountry.isnull(), 'NativeCountry', NativeCountry_mode)\n",
    "    \n",
    "    #drop unnecessary columns\n",
    "    df.drop(labels=['FinalWeight','Education','CapitalGain','CapitalLoss','HoursPerWeek'], axis=1, inplace=True)\n",
    "\n",
    "    #convert categorical data to numerical data using dummies\n",
    "    dummies_WorkClass = pd.get_dummies(df['WorkClass'],prefix='WorkClass')\n",
    "    dummies_MaritalStatus = pd.get_dummies(df['MaritalStatus'], prefix= 'MaritalStatus') \n",
    "    dummies_Occupation = pd.get_dummies(df['Occupation'], prefix= 'Occupation')\n",
    "    dummies_Relationship = pd.get_dummies(df['Relationship'], prefix= 'Relationship')\n",
    "    dummies_Race = pd.get_dummies(df['Race'], prefix= 'Race') \n",
    "    dummies_Sex = pd.get_dummies(df['Sex'], prefix= 'Sex')\n",
    "    dummies_NativeCountry = pd.get_dummies(df['NativeCountry'], prefix= 'NativeCountry')\n",
    "    #dummies_Negative_Investment = pd.get_dummies(df['Negative_Investment'], prefix= 'Negative_Investment')\n",
    "    \n",
    "    #add new dummy columns to the original dataframe\n",
    "    df = pd.concat([df, dummies_WorkClass, dummies_MaritalStatus, dummies_Occupation, dummies_Relationship, \\\n",
    "                    dummies_Race, dummies_Sex, dummies_NativeCountry], axis=1)\n",
    "    #drop orignal categorial data columns so we will be using those numerial dummies\n",
    "    df = df.drop(['WorkClass','MaritalStatus','Occupation', 'Relationship', 'Race', 'Sex', \\\n",
    "                  'NativeCountry'], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Strategy Motivations\n",
    "\n",
    "##### Missing Values\n",
    "As I previously exmaplined, I got rid of the missing values by replace them with the mode values and because the number is not as significant as the totoal number of data samples we have so the drawback will not be that pronounced. Yet it may make it easier for the model to extract the most signifcant feature key.\n",
    "\n",
    "##### Dropped Features and New Feature\n",
    "I dropped'FinalWeight'because it may not be obviously useful to my model, the'HoursPerWeek' may not be useful as it depends on some occupation so some occupation may only need to work for a few hours to make a lot of money while the others only pay a little even though work for a extended period of time. The'Education' is dropped because another column \"EducationLvl\" can represent the same information but with categorical data already. Finally, the 'CapitalGain' and 'CapitalLoss'are dropped and replaced with a new feature column \"Negative_Investment\" with numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "#run the clean function to both training and testing data sets\n",
    "training_data = clean(training_data)\n",
    "test_data = clean(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: I did not convert IncomeBracket to numerical data, because it is our target variable, the model does not need it to build the model so it will be handled separately later. It can be done, however, just not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EducationLvl</th>\n",
       "      <th>IncomeBracket</th>\n",
       "      <th>Negative_Investment</th>\n",
       "      <th>WorkClass_Federal-gov</th>\n",
       "      <th>WorkClass_Local-gov</th>\n",
       "      <th>WorkClass_Never-worked</th>\n",
       "      <th>WorkClass_Private</th>\n",
       "      <th>WorkClass_Self-emp-inc</th>\n",
       "      <th>WorkClass_Self-emp-not-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>NativeCountry_Portugal</th>\n",
       "      <th>NativeCountry_Puerto-Rico</th>\n",
       "      <th>NativeCountry_Scotland</th>\n",
       "      <th>NativeCountry_South</th>\n",
       "      <th>NativeCountry_Taiwan</th>\n",
       "      <th>NativeCountry_Thailand</th>\n",
       "      <th>NativeCountry_Trinadad&amp;Tobago</th>\n",
       "      <th>NativeCountry_United-States</th>\n",
       "      <th>NativeCountry_Vietnam</th>\n",
       "      <th>NativeCountry_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>50-100K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>14</td>\n",
       "      <td>&lt;50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  EducationLvl IncomeBracket  Negative_Investment  \\\n",
       "0   42            10          <50K                    0   \n",
       "1   28            10          <50K                    0   \n",
       "2   24            10       50-100K                    0   \n",
       "3   32             5          <50K                    0   \n",
       "4   55            14          <50K                    0   \n",
       "\n",
       "   WorkClass_Federal-gov  WorkClass_Local-gov  WorkClass_Never-worked  \\\n",
       "0                      0                    0                       0   \n",
       "1                      0                    0                       0   \n",
       "2                      0                    0                       0   \n",
       "3                      0                    0                       0   \n",
       "4                      0                    0                       0   \n",
       "\n",
       "   WorkClass_Private  WorkClass_Self-emp-inc  WorkClass_Self-emp-not-inc  \\\n",
       "0                  0                       0                           0   \n",
       "1                  1                       0                           0   \n",
       "2                  1                       0                           0   \n",
       "3                  0                       0                           1   \n",
       "4                  0                       0                           1   \n",
       "\n",
       "             ...             NativeCountry_Portugal  \\\n",
       "0            ...                                  0   \n",
       "1            ...                                  0   \n",
       "2            ...                                  0   \n",
       "3            ...                                  0   \n",
       "4            ...                                  0   \n",
       "\n",
       "   NativeCountry_Puerto-Rico  NativeCountry_Scotland  NativeCountry_South  \\\n",
       "0                          0                       0                    0   \n",
       "1                          0                       0                    0   \n",
       "2                          0                       0                    0   \n",
       "3                          0                       0                    0   \n",
       "4                          0                       0                    0   \n",
       "\n",
       "   NativeCountry_Taiwan  NativeCountry_Thailand  \\\n",
       "0                     0                       0   \n",
       "1                     0                       0   \n",
       "2                     0                       0   \n",
       "3                     0                       0   \n",
       "4                     0                       0   \n",
       "\n",
       "   NativeCountry_Trinadad&Tobago  NativeCountry_United-States  \\\n",
       "0                              0                            1   \n",
       "1                              0                            1   \n",
       "2                              0                            1   \n",
       "3                              0                            1   \n",
       "4                              0                            1   \n",
       "\n",
       "   NativeCountry_Vietnam  NativeCountry_Yugoslavia  \n",
       "0                      0                         0  \n",
       "1                      0                         0  \n",
       "2                      0                         0  \n",
       "3                      0                         0  \n",
       "4                      0                         0  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the first 5 rows of training set\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EducationLvl</th>\n",
       "      <th>IncomeBracket</th>\n",
       "      <th>Negative_Investment</th>\n",
       "      <th>WorkClass_Federal-gov</th>\n",
       "      <th>WorkClass_Local-gov</th>\n",
       "      <th>WorkClass_Never-worked</th>\n",
       "      <th>WorkClass_Private</th>\n",
       "      <th>WorkClass_Self-emp-inc</th>\n",
       "      <th>WorkClass_Self-emp-not-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>NativeCountry_Portugal</th>\n",
       "      <th>NativeCountry_Puerto-Rico</th>\n",
       "      <th>NativeCountry_Scotland</th>\n",
       "      <th>NativeCountry_South</th>\n",
       "      <th>NativeCountry_Taiwan</th>\n",
       "      <th>NativeCountry_Thailand</th>\n",
       "      <th>NativeCountry_Trinadad&amp;Tobago</th>\n",
       "      <th>NativeCountry_United-States</th>\n",
       "      <th>NativeCountry_Vietnam</th>\n",
       "      <th>NativeCountry_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57</td>\n",
       "      <td>10</td>\n",
       "      <td>50-100K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>13</td>\n",
       "      <td>&lt;50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>&lt;50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>&lt;50K</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>&lt;50K</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  EducationLvl IncomeBracket  Negative_Investment  \\\n",
       "0   57            10       50-100K                    0   \n",
       "1   35            13          <50K                    0   \n",
       "2   26            13          <50K                    0   \n",
       "3   27            13          <50K                    0   \n",
       "4   21             9          <50K                    0   \n",
       "\n",
       "   WorkClass_Federal-gov  WorkClass_Local-gov  WorkClass_Never-worked  \\\n",
       "0                      0                    0                       0   \n",
       "1                      0                    0                       0   \n",
       "2                      0                    0                       0   \n",
       "3                      1                    0                       0   \n",
       "4                      0                    0                       0   \n",
       "\n",
       "   WorkClass_Private  WorkClass_Self-emp-inc  WorkClass_Self-emp-not-inc  \\\n",
       "0                  0                       0                           1   \n",
       "1                  1                       0                           0   \n",
       "2                  1                       0                           0   \n",
       "3                  0                       0                           0   \n",
       "4                  1                       0                           0   \n",
       "\n",
       "             ...             NativeCountry_Portugal  \\\n",
       "0            ...                                  0   \n",
       "1            ...                                  0   \n",
       "2            ...                                  0   \n",
       "3            ...                                  0   \n",
       "4            ...                                  0   \n",
       "\n",
       "   NativeCountry_Puerto-Rico  NativeCountry_Scotland  NativeCountry_South  \\\n",
       "0                          0                       0                    0   \n",
       "1                          0                       0                    0   \n",
       "2                          0                       0                    0   \n",
       "3                          0                       0                    0   \n",
       "4                          0                       0                    0   \n",
       "\n",
       "   NativeCountry_Taiwan  NativeCountry_Thailand  \\\n",
       "0                     0                       0   \n",
       "1                     0                       0   \n",
       "2                     0                       0   \n",
       "3                     0                       0   \n",
       "4                     0                       0   \n",
       "\n",
       "   NativeCountry_Trinadad&Tobago  NativeCountry_United-States  \\\n",
       "0                              0                            1   \n",
       "1                              0                            1   \n",
       "2                              0                            1   \n",
       "3                              0                            1   \n",
       "4                              0                            0   \n",
       "\n",
       "   NativeCountry_Vietnam  NativeCountry_Yugoslavia  \n",
       "0                      0                         0  \n",
       "1                      0                         0  \n",
       "2                      0                         0  \n",
       "3                      0                         0  \n",
       "4                      0                         0  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the first 5 rows of testing set\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/seaborn/categorical.py:1460: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
      "  stat_data = remove_na(group_data)\n",
      "/Applications/anaconda3/lib/python3.6/site-packages/seaborn/categorical.py:1508: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
      "  stat_data = remove_na(group_data[hue_mask])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10c8693c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA38AAARnCAYAAABEld/3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5K8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113e55048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#setup the plot and plot 3 graphs from the training data set\n",
    "fig, (axis1,axis2,axis3) = plt.subplots(3,1,figsize=(15,20))\n",
    "\n",
    "sns.countplot(x='IncomeBracket', data=training_data, ax=axis1)\n",
    "sns.countplot(x='IncomeBracket', hue=\"Sex_Male\", data=training_data, ax=axis2)\n",
    "sns.countplot(x='IncomeBracket', hue=\"EducationLvl\", data=training_data, ax=axis3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Discussion\n",
    "Graph1: the plot shows the general demographical distribution of people's income, from the graph it shows that the majority of people are in the < 50K IncomeBracket range, this will help us understand the trend and develop an expectation of the data analysis that most people should fall into this category.\n",
    "\n",
    "Graph2: this plot invesitigate the gender distribution among all three incomebrackets, across all IncomeBracket range, there is always more male than female, this plotentially may reveal and that there are more male in the workplace than female and both male and female have more people making less than 50K.\n",
    "\n",
    "Graph3: the plot shows the occupation distribution among all three icomebrackets, we can see both highly eduacated and less educated people making < 50K but to be able to make > 100K, one most likely is highly educated. The information gathered here gave us before-hand expections of the outcomes of the data classification, that highly eduacated people with advanced occupation are likely to make a lot more money."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal components analysis (PCA) to visualize feature improtance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Seperate the target varaible - \"IncomeBracket\" column from the orignal dataframe\n",
    "#Put them into feature objects and target object to prepare for subsequent analysis\n",
    "training_data_features=training_data.drop(['IncomeBracket'], axis=1).values\n",
    "training_data_targets=training_data.IncomeBracket.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import revelant modules\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#since some features are measured in different scales, I normalized them first\n",
    "training_data_features_std = StandardScaler().fit_transform(training_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find the covariance matrix, eigenvalue/eigenvectors of the features\n",
    "cov_mat = np.cov(training_data_features_std.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rank each eigen values and get each individual explained varaince\n",
    "tot = sum(eig_vals)\n",
    "var_exp = [round((i / tot)*100, 3) for i in sorted(eig_vals, reverse=True)]\n",
    "#compute an accumlated explained variance\n",
    "cum_var_exp = np.cumsum(var_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAAI4CAYAAACcFxlBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121610198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the individual explained varaince and accumlated explained variance\n",
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(15, 8))\n",
    "\n",
    "    plt.bar(range(86), var_exp, alpha=0.5, align='center',\n",
    "            label='individual explained variance')\n",
    "    plt.step(range(86), cum_var_exp, where='mid',\n",
    "             label='cumulative explained variance')\n",
    "    \n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Principal components')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance Explanation and Selection Justifications\n",
    "#Depends on the goal of how much explained covariance you want to get, we can pick how many principal components we want to use. In this case, the first 5 principal components may explain about 20% which is bad, however, to get 80% of explained covariance, we need to have around 55 principal compoents which is not a whole lot improvment from the original total of 86  features that would gave us 100% explained covaraince. As a general rule of thumb, I will use 55 principal components to achieve a 80% explained covariance. From the individual explained varaince values, it can be concluded that Age and EducationLv are most related to an individual's incomebracket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variation per principal component: [ 0.05008886  0.02976867  0.02912312  0.02354502  0.02105475  0.02026472\n",
      "  0.01856753  0.01639417  0.01540354  0.0144346   0.01434858  0.01419317\n",
      "  0.01351854  0.01339128  0.01323561  0.01309324  0.01288784  0.01275413\n",
      "  0.01264791  0.0125775   0.01246727  0.01231747  0.0121576   0.01213756\n",
      "  0.01207933  0.01196086  0.01187757  0.01182707  0.01173664  0.01171752\n",
      "  0.01169825  0.01166398  0.01165473  0.01164988  0.01164651  0.01164293\n",
      "  0.01164168  0.01163686  0.01163004  0.0116254   0.01161141  0.01160235\n",
      "  0.01159062  0.0115866   0.01156339  0.01155205  0.01151368  0.01147721\n",
      "  0.01143415  0.01140399  0.01137909  0.01133023  0.01127789  0.0112136\n",
      "  0.01116254]\n"
     ]
    }
   ],
   "source": [
    "#pick the number of principle components to be used as 55\n",
    "#fit and transform PCA and print out the explained varaince ratios\n",
    "pca = PCA(n_components=55)\n",
    "traning_data_pca = pca.fit_transform(training_data_features_std)\n",
    "print ('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection Discussion\n",
    "Up to this point, I have cleaned the data(fill missing values and convert categorical data to numerical values), dropped unnecessary features, added a new feature based on other features and selected important fetures to be used for subsequent analysis. Feature engineering is useful as better features means better results from the model, also it simplify the model and thus reducing processing time and yields better flexibility. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#import machine learning modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "try:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "except:\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "try:\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "except:\n",
    "    from sklearn.grid_search import GridSearchCV\n",
    "try:\n",
    "    from sklearn.model_selection import learning_curve\n",
    "except:\n",
    "    from sklearn.learning_curve import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X is the features selected using PCA with 55 principal components\n",
    "#y is the target varaible - incomebracket\n",
    "X = traning_data_pca\n",
    "y = training_data_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define a 10 kfold function\n",
    "def run_kfold(clf):\n",
    "    \n",
    "    #run KFold with 10 folds instead of the default 3\n",
    "    #on the 24421 records in the training_data\n",
    "    kf = KFold(24421, n_folds=10)\n",
    "    \n",
    "    outcomes = []\n",
    "    fold = 0\n",
    "    \n",
    "    for train_index, test_index in kf:\n",
    "        fold += 1\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        \n",
    "        #using accurancy score\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        outcomes.append(accuracy)\n",
    "        print(\"Fold {0} accuracy: {1}\".format(fold, accuracy))   \n",
    "    \n",
    "    #compute an average accurancy score of the 10 results\n",
    "    mean_outcome = np.mean(outcomes)\n",
    "    print(\"Mean Accuracy: {0}\".format(mean_outcome)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1 - Random Forest Classifier\n",
    "Model tunning included using Grid_Search to try out differnt parameter combinations\n",
    "and find out the best set of paramaters and use it for the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=8, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=9, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose the type of classifier. \n",
    "rdc = RandomForestClassifier()\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "parameters = {'n_estimators': [4, 6, 9], \n",
    "              'max_features': ['log2', 'sqrt','auto'], \n",
    "              'criterion': ['entropy', 'gini'],\n",
    "              'max_depth': [2, 3, 5, 10], \n",
    "              'min_samples_split': [2, 3, 5],\n",
    "              'min_samples_leaf': [1,5,8]\n",
    "             }\n",
    "\n",
    "# Use accuracy_score for comparing different parameter combinations. \n",
    "acc_scorer_rdc = make_scorer(accuracy_score)\n",
    "\n",
    "# Run the grid search for the Random Forest classifier\n",
    "grid_obj_rdc = GridSearchCV(rdc, parameters, scoring=acc_scorer_rdc)\n",
    "grid_obj_rdc = grid_obj_rdc.fit(X_train, y_train)\n",
    "\n",
    "# Set our classifier, rdc, to the have the best combination of parameters\n",
    "rdc = grid_obj_rdc.best_estimator_\n",
    "\n",
    "# Fit the selected classifier to the training data\n",
    "rdc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.782994404258\n"
     ]
    }
   ],
   "source": [
    "#predict the results for X_test and print out the accuracy score\n",
    "predictions_rdc = rdc.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions_rdc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 accuracy: 0.7830536225951699\n",
      "Fold 2 accuracy: 0.7858312858312858\n",
      "Fold 3 accuracy: 0.7800982800982801\n",
      "Fold 4 accuracy: 0.8001638001638002\n",
      "Fold 5 accuracy: 0.7952497952497952\n",
      "Fold 6 accuracy: 0.7895167895167895\n",
      "Fold 7 accuracy: 0.7858312858312858\n",
      "Fold 8 accuracy: 0.7866502866502867\n",
      "Fold 9 accuracy: 0.7895167895167895\n",
      "Fold 10 accuracy: 0.7731367731367731\n",
      "Mean Accuracy: 0.7869048708590256\n"
     ]
    }
   ],
   "source": [
    "#run a seprated kfold with the model at its best estimator\n",
    "run_kfold(rdc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier Discussion\n",
    "K-fold shows little variaitions accoress the folds so the accruacy is stable around the mean at 78%\n",
    "Random forest classifier creates a set of decision trees from randomly selected subset of training set. It then aggregates the votes from different decision trees to decide the final class of the test object. Pros: reduced variance (relative to regular trees) Cons: not as easy to visually interpret. I chose this one to compare against other classifier and it is easy to implememnt and useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2 - Logistic Regression\n",
    "Model tunning included using Grid_Search to try out differnt parameter combinations\n",
    "and find out the best set of paramaters and use it for the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.5, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose the type of classifier. \n",
    "lg = LogisticRegression(random_state=42, penalty='l1')\n",
    "parameters = {'C':[0.5]}\n",
    "\n",
    "# Use classification accuracy to compare parameter combinations\n",
    "acc_scorer_lg = make_scorer(accuracy_score)\n",
    "\n",
    "# Run a grid search for the Logistic Regression classifier and all the selected parameters\n",
    "grid_obj_lg = GridSearchCV(lg, parameters, scoring=acc_scorer_lg)\n",
    "grid_obj_lg = grid_obj_lg.fit(X_train, y_train)\n",
    "\n",
    "# Set our classifier, lg, to have the best combination of parameters\n",
    "lg = grid_obj_lg.best_estimator_\n",
    "\n",
    "# Fit the selected classifier to the training data. \n",
    "lg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.786542923434\n"
     ]
    }
   ],
   "source": [
    "#predict the results for X_test and print out the accuracy score\n",
    "predictions_lg = lg.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions_lg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 accuracy: 0.7900122799836267\n",
      "Fold 2 accuracy: 0.7821457821457821\n",
      "Fold 3 accuracy: 0.7788697788697788\n",
      "Fold 4 accuracy: 0.7968877968877969\n",
      "Fold 5 accuracy: 0.7948402948402948\n",
      "Fold 6 accuracy: 0.7948402948402948\n",
      "Fold 7 accuracy: 0.7825552825552825\n",
      "Fold 8 accuracy: 0.778050778050778\n",
      "Fold 9 accuracy: 0.7866502866502867\n",
      "Fold 10 accuracy: 0.782964782964783\n",
      "Mean Accuracy: 0.7867817357788705\n"
     ]
    }
   ],
   "source": [
    "#run a seprated kfold with the model at its best estimator\n",
    "run_kfold(lg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Classifier Discussion\n",
    "K-fold shows little variaitions accoress the folds so the accruacy is stable around the mean at 78%\n",
    "Logistic Regression Predicts Probabilities so it predict how likely a particulate sample belong to a certain class by calculating the probobility for each class and then pick the highest. Pros: low variance Cons: high bias. I chose this one to compare against other classifier and it is easy to implememnt and useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3 - K-Nearest Neighbors\n",
    "Model tunning included using Grid_Search to try out differnt parameter combinations\n",
    "and find out the best set of paramaters and use it for the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import module\n",
    "import sklearn.neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose the type of classifier. \n",
    "knn = sklearn.neighbors.KNeighborsClassifier()\n",
    "\n",
    "k = np.arange(20)+1\n",
    "parameters = {'n_neighbors': k}\n",
    "\n",
    "# Use classification accuracy to compare parameter combinations\n",
    "acc_scorer_knn = make_scorer(accuracy_score)\n",
    "\n",
    "# Run a grid search for the K-Nearest Neighbors classifier and all the selected parameters\n",
    "grid_obj_knn = GridSearchCV(knn, parameters, scoring=acc_scorer_knn)\n",
    "grid_obj_knn = grid_obj_knn.fit(X_train, y_train)\n",
    "\n",
    "# Set our classifier, knn, to have the best combination of parameters\n",
    "knn = grid_obj_knn.best_estimator_\n",
    "\n",
    "# Fit the selected classifier to the training data. \n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.782039033711\n"
     ]
    }
   ],
   "source": [
    "#predict the results for X_test and print out the accuracy score\n",
    "predictions_knn = knn.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 accuracy: 0.7777322963569382\n",
      "Fold 2 accuracy: 0.7870597870597871\n",
      "Fold 3 accuracy: 0.769041769041769\n",
      "Fold 4 accuracy: 0.7977067977067978\n",
      "Fold 5 accuracy: 0.7911547911547911\n",
      "Fold 6 accuracy: 0.7841932841932842\n",
      "Fold 7 accuracy: 0.7854217854217854\n",
      "Fold 8 accuracy: 0.782964782964783\n",
      "Fold 9 accuracy: 0.7858312858312858\n",
      "Fold 10 accuracy: 0.7723177723177723\n",
      "Mean Accuracy: 0.7833424352048994\n"
     ]
    }
   ],
   "source": [
    "#run a seprated kfold with the model at its best estimator\n",
    "run_kfold(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  K-Nearest Neighbors Classifier Discussion\n",
    "K-fold shows little variaitions accoress the folds so the accruacy is stable around the mean at 78%\n",
    "K-nearest neighbor classifier essentially formes a majority vote between the K most similar instances to a given “unseen” observation. Similarity is defined according to a distance metric between two data points. Pros: simple to understand and easy to implement. Cons: computationally expensive. I chose this one to compare against other classifier and it is easy to implememnt and useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Model 4 - Decision Tree\n",
    "Model tunning included using Grid_Search to try out differnt parameter combinations\n",
    "and find out the best set of paramaters and use it for the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import module\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose the type of classifier. \n",
    "tre = tree.DecisionTreeClassifier()\n",
    "\n",
    "parameters = {'criterion':['gini','entropy'], \\\n",
    "              'max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150]}\n",
    "\n",
    "# Use classification accuracy to compare parameter combinations\n",
    "acc_scorer_tre = make_scorer(accuracy_score)\n",
    "\n",
    "# Run a grid search for the Decision Tree classifier and all the selected parameters\n",
    "grid_obj_tre = GridSearchCV(tre, parameters, scoring=acc_scorer_tre)\n",
    "grid_obj_tre = grid_obj_tre.fit(X_train, y_train)\n",
    "\n",
    "# Set our classifier, tre, to have the best combination of parameters\n",
    "tre = grid_obj_tre.best_estimator_\n",
    "\n",
    "# Fit the selected classifier to the training data. \n",
    "tre.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.785178108366\n"
     ]
    }
   ],
   "source": [
    "#predict the results for X_test and print out the accuracy score\n",
    "predictions_tre = tre.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions_tre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 accuracy: 0.7851002865329513\n",
      "Fold 2 accuracy: 0.7825552825552825\n",
      "Fold 3 accuracy: 0.7698607698607699\n",
      "Fold 4 accuracy: 0.7923832923832924\n",
      "Fold 5 accuracy: 0.7923832923832924\n",
      "Fold 6 accuracy: 0.785012285012285\n",
      "Fold 7 accuracy: 0.7825552825552825\n",
      "Fold 8 accuracy: 0.7800982800982801\n",
      "Fold 9 accuracy: 0.7854217854217854\n",
      "Fold 10 accuracy: 0.778050778050778\n",
      "Mean Accuracy: 0.7833421334853999\n"
     ]
    }
   ],
   "source": [
    "#run a seprated kfold with the model at its best estimator\n",
    "run_kfold(tre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Decision Tree Classifier Discussion\n",
    "K-fold shows little variaitions accoress the folds so the accruacy is stable around the mean at 78%\n",
    "The decision tree is used to visually and explicitly represent decisions and decision making. It uses a tree-like model of decisions. So growing a tree involves deciding on which features to choose and what conditions to use for splitting, along with knowing when to stop. Pros: easy to interpret visually when the trees only contain several levels. Cons: prone to overfitting. I chose this one to compare against other classifier and it is easy to implememnt and useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Across Models\n",
    "The Accurancy Scores show that the best classifiers are Random Forest Classifier and Logistic Regression with an overall accurancy of 78.7%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance measurements and why different measurements?\n",
    "The measurements investigated here for the four models are: Accuracy, True Positive Rate and False Positive Rate.\n",
    "The accuracy alone is not always a good indicator of how good a classfier is so I use 2 additinal measurements.\n",
    "\n",
    "The False Positive Rate refers to the probability of falsely rejecting the null hypothesis for a particular test so we want it to be low, while True Positive Rate measures the proportion of positives that are correctly identified so we need it to be high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import module\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define a function to find the confusion matrix for computing False Positive Rate and True Positive Rate\n",
    "def find_matrx (confu):\n",
    "    \n",
    "    FP = confu.sum(axis=0) - np.diag(confu)  \n",
    "    FN = confu.sum(axis=1) - np.diag(confu)\n",
    "    TP = np.diag(confu)\n",
    "    TN = confu.sum() - (FP + FN + TP)\n",
    "    \n",
    "    true_positive_rate = TP.sum()/float((TP+FN).sum())\n",
    "    false_positive_rate = FP.sum() / float((TN + FP).sum())\n",
    "    \n",
    "    return ('True Positive Rate = %f' %true_positive_rate, 'False Positive Rate= %f' %false_positive_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1 - Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Class &lt;50K</th>\n",
       "      <th>Predicted Class 50-100K</th>\n",
       "      <th>Predicted Class &gt;100K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Class &lt;50K</th>\n",
       "      <td>463</td>\n",
       "      <td>729</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Class 50-100K</th>\n",
       "      <td>273</td>\n",
       "      <td>5270</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Class &gt;100K</th>\n",
       "      <td>233</td>\n",
       "      <td>339</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Predicted Class <50K  Predicted Class 50-100K  \\\n",
       "True Class <50K                      463                      729   \n",
       "True Class 50-100K                   273                     5270   \n",
       "True Class >100K                     233                      339   \n",
       "\n",
       "                    Predicted Class >100K  \n",
       "True Class <50K                         7  \n",
       "True Class 50-100K                      9  \n",
       "True Class >100K                        4  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_rdc = metrics.confusion_matrix(y_test, predictions_rdc)\n",
    "pd.DataFrame(confusion_rdc, \\\n",
    "             columns=['Predicted Class <50K', 'Predicted Class 50-100K', 'Predicted Class >100K'], \\\n",
    "             index=['True Class <50K', 'True Class 50-100K', 'True Class >100K'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('True Positive Rate = 0.782994', 'False Positive Rate= 0.108503')\n",
      "Overall accuracy = 0.782994\n"
     ]
    }
   ],
   "source": [
    "print (find_matrx(confusion_rdc))\n",
    "print ('Overall accuracy = %f'%accuracy_score(y_test, predictions_rdc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Class &lt;50K</th>\n",
       "      <th>Predicted Class 50-100K</th>\n",
       "      <th>Predicted Class &gt;100K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Class &lt;50K</th>\n",
       "      <td>511</td>\n",
       "      <td>684</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Class 50-100K</th>\n",
       "      <td>302</td>\n",
       "      <td>5248</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Class &gt;100K</th>\n",
       "      <td>263</td>\n",
       "      <td>309</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Predicted Class <50K  Predicted Class 50-100K  \\\n",
       "True Class <50K                      511                      684   \n",
       "True Class 50-100K                   302                     5248   \n",
       "True Class >100K                     263                      309   \n",
       "\n",
       "                    Predicted Class >100K  \n",
       "True Class <50K                         4  \n",
       "True Class 50-100K                      2  \n",
       "True Class >100K                        4  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mconfusion_lg = metrics.confusion_matrix(y_test, predictions_lg)\n",
    "pd.DataFrame(mconfusion_lg, \\\n",
    "             columns=['Predicted Class <50K', 'Predicted Class 50-100K', 'Predicted Class >100K'], \\\n",
    "             index=['True Class <50K', 'True Class 50-100K', 'True Class >100K'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('True Positive Rate = 0.786543', 'False Positive Rate= 0.106729')\n",
      "Overall accuracy = 0.786543\n"
     ]
    }
   ],
   "source": [
    "print (find_matrx(mconfusion_lg))\n",
    "print ('Overall accuracy = %f'%accuracy_score(y_test, predictions_lg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3 - K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Class &lt;50K</th>\n",
       "      <th>Predicted Class 50-100K</th>\n",
       "      <th>Predicted Class &gt;100K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Class &lt;50K</th>\n",
       "      <td>522</td>\n",
       "      <td>657</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Class 50-100K</th>\n",
       "      <td>344</td>\n",
       "      <td>5192</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Class &gt;100K</th>\n",
       "      <td>251</td>\n",
       "      <td>309</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Predicted Class <50K  Predicted Class 50-100K  \\\n",
       "True Class <50K                      522                      657   \n",
       "True Class 50-100K                   344                     5192   \n",
       "True Class >100K                     251                      309   \n",
       "\n",
       "                    Predicted Class >100K  \n",
       "True Class <50K                        20  \n",
       "True Class 50-100K                     16  \n",
       "True Class >100K                       16  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mconfusion_knn = metrics.confusion_matrix(y_test, predictions_knn)\n",
    "pd.DataFrame(mconfusion_knn, \\\n",
    "             columns=['Predicted Class <50K', 'Predicted Class 50-100K', 'Predicted Class >100K'], \\\n",
    "             index=['True Class <50K', 'True Class 50-100K', 'True Class >100K'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('True Positive Rate = 0.782039', 'False Positive Rate= 0.108980')\n",
      "Overall accuracy = 0.782039\n"
     ]
    }
   ],
   "source": [
    "print (find_matrx(mconfusion_knn))\n",
    "print ('Overall accuracy = %f'%accuracy_score(y_test, predictions_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 4 - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Class &lt;50K</th>\n",
       "      <th>Predicted Class 50-100K</th>\n",
       "      <th>Predicted Class &gt;100K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Class &lt;50K</th>\n",
       "      <td>505</td>\n",
       "      <td>694</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Class 50-100K</th>\n",
       "      <td>304</td>\n",
       "      <td>5248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Class &gt;100K</th>\n",
       "      <td>253</td>\n",
       "      <td>323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Predicted Class <50K  Predicted Class 50-100K  \\\n",
       "True Class <50K                      505                      694   \n",
       "True Class 50-100K                   304                     5248   \n",
       "True Class >100K                     253                      323   \n",
       "\n",
       "                    Predicted Class >100K  \n",
       "True Class <50K                         0  \n",
       "True Class 50-100K                      0  \n",
       "True Class >100K                        0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mconfusion_tre = metrics.confusion_matrix(y_test, predictions_tre)\n",
    "pd.DataFrame(mconfusion_tre, \\\n",
    "             columns=['Predicted Class <50K', 'Predicted Class 50-100K', 'Predicted Class >100K'], \\\n",
    "             index=['True Class <50K', 'True Class 50-100K', 'True Class >100K'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('True Positive Rate = 0.785178', 'False Positive Rate= 0.107411')\n",
      "Overall accuracy = 0.785178\n"
     ]
    }
   ],
   "source": [
    "print (find_matrx(mconfusion_tre))\n",
    "print ('Overall accuracy = %f'%accuracy_score(y_test, predictions_tre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performace Measurements Conclusion\n",
    "The Overall Accuracy scores and the True Positive Rate show that the Logistic Regression Classifier is the best with 78.7% accuracy and 78.7% True Positive Rate and a moderate low False Positive Rate of 10.67%. However, Random Forest classifier also has a very similar perfermace result with 78.3% accuracy and True Positive Rate and a 10.85% low False Positive Rate\n",
    "Therefore, I will use both the Random Forest Classifier and Logistic Regression Classifier at their best parameters for the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Seperate the target varaible - \"IncomeBracket\" column from the orignal dataframe\n",
    "#Put them into feature objects and target object to prepare for subsequent analysis\n",
    "test_data_features=test_data.drop(['IncomeBracket'], axis=1).values\n",
    "test_data_targets=test_data.IncomeBracket.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#Normalize the feature values as they were measured in differnt scales\n",
    "test_data_features_std = StandardScaler().fit_transform(test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Similarly, using 55 PCA principal components to get features from the featuture objects\n",
    "pca_test = PCA(n_components=55)\n",
    "test_data_pca = pca_test.fit_transform(test_data_features_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all 55 PCA principal components are used as the predictors/features\n",
    "#y-all the incomebracket values are the target\n",
    "X = test_data_pca\n",
    "y = test_data_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.749160592908\n"
     ]
    }
   ],
   "source": [
    "#Using the trained Random Forest Classifier at its best parameters to predict and print the score \n",
    "predictions_rdc_test = rdc.predict(X)\n",
    "print(accuracy_score(y, predictions_rdc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.765211694374\n"
     ]
    }
   ],
   "source": [
    "#Using my trained optimal model - Logistic Regression Classifier at its best parameters to predict and print the score \n",
    "predictions_lg_test = lg.predict(X)\n",
    "print(accuracy_score(y, predictions_lg_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Discussion\n",
    "As previously explained, I picked the Logistic Regression Classifier as my optimal model, however, since the Random Forest Classifier had a very similar performace, I used both Logistic Regression and Random Forest for the final testing.\n",
    "\n",
    "Model performace - Logistic Regression Model accurancy score droped from 78.7% down to 76.5%, while the Random Forest Classifier droped from 78.3% down to 74.9%. The accuracy decreases are expected because the models were built using a different set of data, the model may represent that dataset well but it may be limited in describing a new set of data. Regardless, the smaller decrease of accuracy with Logistic Regression Model futher indicated that the Logistic Regression is a better classifier in this case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
